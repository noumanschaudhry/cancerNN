{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevent libreries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas.api.types as ptypes\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to change the classes from M or B to 1 / 0 respectivly \n",
    "def into_num(classify):\n",
    "    if (classify == 'B'):\n",
    "        return(0)\n",
    "    else:\n",
    "        return(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get all the columns name in view\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#csv is loaded from the given location and the given names are added to the columns\n",
    "csv_loc = '..\\\\'\n",
    "csv_name= 'Exercise1 - data.csv'\n",
    "col_names=[\"PID\", \"Class\", \"Radius_mean\", \"Texture_mean\", \"Perimeter_mean\", \"Area_mean\",\"Smoothness_mean\",\"Compactness_mean\",\"Concavity_mean\",\"Concave-points_mean\",\"Symmatry_mean\",\"Fractal-dimension_mean\",\"Radius_SE\", \"Texture_SE\", \"Perimeter_SE\", \"Area_SE\",\"Smoothness_SE\",\"Compactness_SE\",\"Concavity_SE\",\"Concave-points_SE\",\"Symmatry_SE\",\"Fractal-dimension_SE\",\"Radius_largest\", \"Texture_largest\", \"Perimeter_largest\", \"Area_largest\",\"Smoothness_largest\",\"Compactness_largest\",\"Concavity_largest\",\"Concave-points_largest\",\"Symmatry_largest\",\"Fractal-dimension_largest\"]\n",
    "df = pd.read_csv(csv_loc+csv_name, names=col_names)\n",
    "\n",
    "#get the dimensions of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PID                          0\n",
       "Class                        0\n",
       "Radius_mean                  0\n",
       "Texture_mean                 0\n",
       "Perimeter_mean               0\n",
       "Area_mean                    0\n",
       "Smoothness_mean              0\n",
       "Compactness_mean             0\n",
       "Concavity_mean               0\n",
       "Concave-points_mean          0\n",
       "Symmatry_mean                0\n",
       "Fractal-dimension_mean       0\n",
       "Radius_SE                    0\n",
       "Texture_SE                   0\n",
       "Perimeter_SE                 0\n",
       "Area_SE                      0\n",
       "Smoothness_SE                0\n",
       "Compactness_SE               0\n",
       "Concavity_SE                 0\n",
       "Concave-points_SE            0\n",
       "Symmatry_SE                  0\n",
       "Fractal-dimension_SE         0\n",
       "Radius_largest               0\n",
       "Texture_largest              0\n",
       "Perimeter_largest            0\n",
       "Area_largest                 0\n",
       "Smoothness_largest           0\n",
       "Compactness_largest          0\n",
       "Concavity_largest            0\n",
       "Concave-points_largest       0\n",
       "Symmatry_largest             0\n",
       "Fractal-dimension_largest    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just making sure data has no null values\n",
    "pd.isnull(df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radius_mean</th>\n",
       "      <th>Texture_mean</th>\n",
       "      <th>Perimeter_mean</th>\n",
       "      <th>Area_mean</th>\n",
       "      <th>Smoothness_mean</th>\n",
       "      <th>Compactness_mean</th>\n",
       "      <th>Concavity_mean</th>\n",
       "      <th>Concave-points_mean</th>\n",
       "      <th>Symmatry_mean</th>\n",
       "      <th>Fractal-dimension_mean</th>\n",
       "      <th>Radius_SE</th>\n",
       "      <th>Texture_SE</th>\n",
       "      <th>Perimeter_SE</th>\n",
       "      <th>Area_SE</th>\n",
       "      <th>Smoothness_SE</th>\n",
       "      <th>Compactness_SE</th>\n",
       "      <th>Concavity_SE</th>\n",
       "      <th>Concave-points_SE</th>\n",
       "      <th>Symmatry_SE</th>\n",
       "      <th>Fractal-dimension_SE</th>\n",
       "      <th>Radius_largest</th>\n",
       "      <th>Texture_largest</th>\n",
       "      <th>Perimeter_largest</th>\n",
       "      <th>Area_largest</th>\n",
       "      <th>Smoothness_largest</th>\n",
       "      <th>Compactness_largest</th>\n",
       "      <th>Concavity_largest</th>\n",
       "      <th>Concave-points_largest</th>\n",
       "      <th>Symmatry_largest</th>\n",
       "      <th>Fractal-dimension_largest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>12.83</td>\n",
       "      <td>22.33</td>\n",
       "      <td>85.26</td>\n",
       "      <td>503.2</td>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.16950</td>\n",
       "      <td>0.06861</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.07254</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>2.257</td>\n",
       "      <td>25.13</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.03858</td>\n",
       "      <td>0.04683</td>\n",
       "      <td>0.01499</td>\n",
       "      <td>0.01680</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>15.20</td>\n",
       "      <td>30.15</td>\n",
       "      <td>105.30</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.1777</td>\n",
       "      <td>0.5343</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.19770</td>\n",
       "      <td>0.3407</td>\n",
       "      <td>0.12430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.08</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>1.383</td>\n",
       "      <td>14.67</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.01698</td>\n",
       "      <td>0.00649</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>14.50</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Radius_mean  Texture_mean  Perimeter_mean  Area_mean  Smoothness_mean  \\\n",
       "229        12.83         22.33           85.26      503.2           0.1088   \n",
       "20         13.08         15.71           85.63      520.0           0.1075   \n",
       "0          17.99         10.38          122.80     1001.0           0.1184   \n",
       "\n",
       "     Compactness_mean  Concavity_mean  Concave-points_mean  Symmatry_mean  \\\n",
       "229            0.1799         0.16950              0.06861         0.2123   \n",
       "20             0.1270         0.04568              0.03110         0.1967   \n",
       "0              0.2776         0.30010              0.14710         0.2419   \n",
       "\n",
       "     Fractal-dimension_mean  Radius_SE  Texture_SE  Perimeter_SE  Area_SE  \\\n",
       "229                 0.07254     0.3061      1.0690         2.257    25.13   \n",
       "20                  0.06811     0.1852      0.7477         1.383    14.67   \n",
       "0                   0.07871     1.0950      0.9053         8.589   153.40   \n",
       "\n",
       "     Smoothness_SE  Compactness_SE  Concavity_SE  Concave-points_SE  \\\n",
       "229       0.006983         0.03858       0.04683            0.01499   \n",
       "20        0.004097         0.01898       0.01698            0.00649   \n",
       "0         0.006399         0.04904       0.05373            0.01587   \n",
       "\n",
       "     Symmatry_SE  Fractal-dimension_SE  Radius_largest  Texture_largest  \\\n",
       "229      0.01680              0.005617           15.20            30.15   \n",
       "20       0.01678              0.002425           14.50            20.49   \n",
       "0        0.03003              0.006193           25.38            17.33   \n",
       "\n",
       "     Perimeter_largest  Area_largest  Smoothness_largest  Compactness_largest  \\\n",
       "229             105.30         706.0              0.1777               0.5343   \n",
       "20               96.09         630.5              0.1312               0.2776   \n",
       "0               184.60        2019.0              0.1622               0.6656   \n",
       "\n",
       "     Concavity_largest  Concave-points_largest  Symmatry_largest  \\\n",
       "229             0.6282                 0.19770            0.3407   \n",
       "20              0.1890                 0.07283            0.3184   \n",
       "0               0.7119                 0.26540            0.4601   \n",
       "\n",
       "     Fractal-dimension_largest  \n",
       "229                    0.12430  \n",
       "20                     0.08183  \n",
       "0                      0.11890  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seprate the inputs from the output X is input y is the ground truth values\n",
    "X = df.drop(['Class','PID'],axis=1) \n",
    "y = df['Class'] \n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 569\n",
      "mel: 212\n",
      "ben: 357\n"
     ]
    }
   ],
   "source": [
    "#to check the balance of the data\n",
    "\n",
    "print('total: '+str(df.Class.count()))\n",
    "\n",
    "mel = df[df.Class == 'M'].count()\n",
    "print('mel: '+str(mel.Class))\n",
    "\n",
    "ben = df[df.Class == 'B'].count()\n",
    "print('ben: '+str(ben.Class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y =y.apply(into_num)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get seprate traing and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise the input values before the feed\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initilise the model\n",
    "Model = Sequential()\n",
    "\n",
    "#First hidden layer\n",
    "Model.add(Dense(activation='relu',  input_dim=30, units=16,kernel_initializer=\"uniform\"))\n",
    "Model.add(Dropout(rate=0.2))\n",
    "\n",
    "\n",
    "# second hidden layer\n",
    "Model.add(Dense(units=16, kernel_initializer=\"uniform\", activation='relu'))\n",
    "Model.add(Dropout(rate=0.2))\n",
    "\n",
    "#third hidden layer\n",
    "Model.add(Dense(units=8, kernel_initializer=\"uniform\", activation='relu'))\n",
    "Model.add(Dropout(rate=0.2))\n",
    "\n",
    "Model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "#compile the model\n",
    "Model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 0.6929 - acc: 0.6264\n",
      "Epoch 2/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.6923 - acc: 0.6198\n",
      "Epoch 3/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6915 - acc: 0.6198\n",
      "Epoch 4/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6905 - acc: 0.6198\n",
      "Epoch 5/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.6892 - acc: 0.6220\n",
      "Epoch 6/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.6871 - acc: 0.6484\n",
      "Epoch 7/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6840 - acc: 0.7429\n",
      "Epoch 8/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6795 - acc: 0.8396\n",
      "Epoch 9/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.6722 - acc: 0.8791\n",
      "Epoch 10/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.6607 - acc: 0.9077\n",
      "Epoch 11/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.6474 - acc: 0.9231\n",
      "Epoch 12/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6282 - acc: 0.9363\n",
      "Epoch 13/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.6027 - acc: 0.9407\n",
      "Epoch 14/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.5750 - acc: 0.9516\n",
      "Epoch 15/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.5454 - acc: 0.9495\n",
      "Epoch 16/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.5150 - acc: 0.9560\n",
      "Epoch 17/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.4818 - acc: 0.9560\n",
      "Epoch 18/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.4567 - acc: 0.9560\n",
      "Epoch 19/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.4279 - acc: 0.9560\n",
      "Epoch 20/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.4000 - acc: 0.9582\n",
      "Epoch 21/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.3731 - acc: 0.9582\n",
      "Epoch 22/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.3506 - acc: 0.9648\n",
      "Epoch 23/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.3135 - acc: 0.9648\n",
      "Epoch 24/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.2939 - acc: 0.9670\n",
      "Epoch 25/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.2786 - acc: 0.9692\n",
      "Epoch 26/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.2444 - acc: 0.9736\n",
      "Epoch 27/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.2257 - acc: 0.9780\n",
      "Epoch 28/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.2098 - acc: 0.9670\n",
      "Epoch 29/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.1929 - acc: 0.9802\n",
      "Epoch 30/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.1725 - acc: 0.9824\n",
      "Epoch 31/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.1669 - acc: 0.9846\n",
      "Epoch 32/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1371 - acc: 0.9846\n",
      "Epoch 33/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.1480 - acc: 0.9824\n",
      "Epoch 34/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1356 - acc: 0.9846\n",
      "Epoch 35/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.1263 - acc: 0.9802\n",
      "Epoch 36/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1163 - acc: 0.9780\n",
      "Epoch 37/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.1111 - acc: 0.9846\n",
      "Epoch 38/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1092 - acc: 0.9890\n",
      "Epoch 39/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.1214 - acc: 0.9780\n",
      "Epoch 40/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1022 - acc: 0.9846\n",
      "Epoch 41/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1013 - acc: 0.9846\n",
      "Epoch 42/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0926 - acc: 0.9868\n",
      "Epoch 43/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0847 - acc: 0.9846\n",
      "Epoch 44/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0948 - acc: 0.9802\n",
      "Epoch 45/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0834 - acc: 0.9868\n",
      "Epoch 46/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0851 - acc: 0.9890\n",
      "Epoch 47/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0759 - acc: 0.9890\n",
      "Epoch 48/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0759 - acc: 0.9890\n",
      "Epoch 49/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0825 - acc: 0.9846\n",
      "Epoch 50/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0790 - acc: 0.9890\n",
      "Epoch 51/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0843 - acc: 0.9890\n",
      "Epoch 52/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0931 - acc: 0.9890\n",
      "Epoch 53/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0767 - acc: 0.9890\n",
      "Epoch 54/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0764 - acc: 0.9890\n",
      "Epoch 55/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0610 - acc: 0.9912\n",
      "Epoch 56/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0702 - acc: 0.9912\n",
      "Epoch 57/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0806 - acc: 0.9912\n",
      "Epoch 58/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0763 - acc: 0.9890\n",
      "Epoch 59/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0701 - acc: 0.9912\n",
      "Epoch 60/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0938 - acc: 0.9912\n",
      "Epoch 61/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0674 - acc: 0.9912\n",
      "Epoch 62/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0678 - acc: 0.9912\n",
      "Epoch 63/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0884 - acc: 0.9934\n",
      "Epoch 64/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0662 - acc: 0.9912\n",
      "Epoch 65/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0530 - acc: 0.9934\n",
      "Epoch 66/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0617 - acc: 0.9912\n",
      "Epoch 67/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0638 - acc: 0.9912\n",
      "Epoch 68/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0563 - acc: 0.9912\n",
      "Epoch 69/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0669 - acc: 0.9890\n",
      "Epoch 70/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0644 - acc: 0.9912\n",
      "Epoch 71/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0662 - acc: 0.9912\n",
      "Epoch 72/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0623 - acc: 0.9912\n",
      "Epoch 73/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0564 - acc: 0.9912\n",
      "Epoch 74/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0653 - acc: 0.9934\n",
      "Epoch 75/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0671 - acc: 0.9912\n",
      "Epoch 76/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0697 - acc: 0.9934\n",
      "Epoch 77/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0601 - acc: 0.9912\n",
      "Epoch 78/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0615 - acc: 0.9934\n",
      "Epoch 79/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0682 - acc: 0.9934\n",
      "Epoch 80/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0644 - acc: 0.9934\n",
      "Epoch 81/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0645 - acc: 0.9934\n",
      "Epoch 82/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0647 - acc: 0.9934\n",
      "Epoch 83/150\n",
      "455/455 [==============================] - 0s 48us/step - loss: 0.0393 - acc: 0.9934\n",
      "Epoch 84/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0701 - acc: 0.9934\n",
      "Epoch 85/150\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.0526 - acc: 0.9912\n",
      "Epoch 86/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0498 - acc: 0.9934\n",
      "Epoch 87/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0566 - acc: 0.9934\n",
      "Epoch 88/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0712 - acc: 0.9890\n",
      "Epoch 89/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0755 - acc: 0.9890\n",
      "Epoch 90/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0479 - acc: 0.9934\n",
      "Epoch 91/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0512 - acc: 0.9934\n",
      "Epoch 92/150\n",
      "455/455 [==============================] - 0s 48us/step - loss: 0.0515 - acc: 0.9934\n",
      "Epoch 93/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0589 - acc: 0.9934\n",
      "Epoch 94/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0587 - acc: 0.9934\n",
      "Epoch 95/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0704 - acc: 0.9912\n",
      "Epoch 96/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0595 - acc: 0.9934\n",
      "Epoch 97/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0495 - acc: 0.9890\n",
      "Epoch 98/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0545 - acc: 0.9912\n",
      "Epoch 99/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0666 - acc: 0.9934\n",
      "Epoch 100/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0656 - acc: 0.9934\n",
      "Epoch 101/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0595 - acc: 0.9912\n",
      "Epoch 102/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.0377 - acc: 0.9912\n",
      "Epoch 103/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0589 - acc: 0.9934\n",
      "Epoch 104/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0662 - acc: 0.9912\n",
      "Epoch 105/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.0723 - acc: 0.9934\n",
      "Epoch 106/150\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0611 - acc: 0.9934\n",
      "Epoch 107/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0658 - acc: 0.9912\n",
      "Epoch 108/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0533 - acc: 0.9934\n",
      "Epoch 109/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0627 - acc: 0.9934\n",
      "Epoch 110/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0604 - acc: 0.9934\n",
      "Epoch 111/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0535 - acc: 0.9934\n",
      "Epoch 112/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0584 - acc: 0.9934\n",
      "Epoch 113/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0616 - acc: 0.9934\n",
      "Epoch 114/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0518 - acc: 0.9912\n",
      "Epoch 115/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0489 - acc: 0.9934\n",
      "Epoch 116/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0426 - acc: 0.9934\n",
      "Epoch 117/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0403 - acc: 0.9934\n",
      "Epoch 118/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0496 - acc: 0.9912\n",
      "Epoch 119/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0483 - acc: 0.9912\n",
      "Epoch 120/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0454 - acc: 0.9934\n",
      "Epoch 121/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0641 - acc: 0.9912\n",
      "Epoch 122/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0524 - acc: 0.9912\n",
      "Epoch 123/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0536 - acc: 0.9912\n",
      "Epoch 124/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0502 - acc: 0.9912\n",
      "Epoch 125/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0559 - acc: 0.9912\n",
      "Epoch 126/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0498 - acc: 0.9934\n",
      "Epoch 127/150\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0651 - acc: 0.9934\n",
      "Epoch 128/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0647 - acc: 0.9934\n",
      "Epoch 129/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0670 - acc: 0.9912\n",
      "Epoch 130/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0445 - acc: 0.9912\n",
      "Epoch 131/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0629 - acc: 0.9912\n",
      "Epoch 132/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0539 - acc: 0.9934\n",
      "Epoch 133/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0526 - acc: 0.9934\n",
      "Epoch 134/150\n",
      "455/455 [==============================] - 0s 44us/step - loss: 0.0586 - acc: 0.9934\n",
      "Epoch 135/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0472 - acc: 0.9934\n",
      "Epoch 136/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0544 - acc: 0.9890\n",
      "Epoch 137/150\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0689 - acc: 0.9912\n",
      "Epoch 138/150\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0369 - acc: 0.9934\n",
      "Epoch 139/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0515 - acc: 0.9934\n",
      "Epoch 140/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0485 - acc: 0.9934\n",
      "Epoch 141/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0458 - acc: 0.9912\n",
      "Epoch 142/150\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0449 - acc: 0.9934\n",
      "Epoch 143/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0498 - acc: 0.9934\n",
      "Epoch 144/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0367 - acc: 0.9934\n",
      "Epoch 145/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0506 - acc: 0.9934\n",
      "Epoch 146/150\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.0571 - acc: 0.9934\n",
      "Epoch 147/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0465 - acc: 0.9934\n",
      "Epoch 148/150\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0442 - acc: 0.9934\n",
      "Epoch 149/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0606 - acc: 0.9934\n",
      "Epoch 150/150\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0653 - acc: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b65ccd94e0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "Model.fit(X_train, y_train, batch_size=100, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b662c0abe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run the test part through the traied model\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "#take scores that are more than 0.5\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "#calculation of the confusion matrix\n",
    "con_mat = confusion_matrix(y_test, y_pred)\n",
    "#plot a seaborn heatmap \n",
    "sns.heatmap(con_mat,annot=True)\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.49122807017544\n"
     ]
    }
   ],
   "source": [
    "correct = 74+36\n",
    "wrong = 3+1\n",
    "total = correct + wrong\n",
    "accuracy = (correct/total)*100\n",
    "print(\"accuracy: \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
